// The Hexa Compiler
// Copyright (C) 2021  Oleg Petrenko
// Copyright (C) 2018  Bogdan Danylchenko
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Lesser General Public License as published by
// the Free Software Foundation, version 3 of the License.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Lesser General Public License for more details.
//
// You should have received a copy of the GNU Lesser General Public License
// along with this program.  If not, see <https://www.gnu.org/licenses/>.

// Array of resulting tokens
class Tokens {
	var token: Buffer // TODO let = new.
	// Values of an unique lexemes, like integers and strings
	var value: [String]
	var meta: [Meta]
	var length: Int
	var line: [Int]
	var column: [Int]
	var fileName: String

	new (tokens, length, values, lines, columns, fileName, meta) {
		this.token = tokens
		this.length = length
		this.value = values
		this.line = lines
		this.column = columns
		this.fileName = fileName
		this.meta = meta
	}
}

// Takes UTF-8 text and returns tokens
class Lexer {
	static fun tokenize(bytes: Buffer, fileName: String): Tokens {
			// Variables
			var position = 0
			let len = bytes.length
			var to = 0
			var s = ""
			var p = 0
			var line = 1
			var columnBase = 0

			// Prefetch
			let params = []
			let tokens = Buffer.alloc(len + 1)
			let meta: [Meta] = []
			var lines = []
			var columns = []

			// Helpers
			// Just add plain token
			@inline fun add(t: Token) {
				tokens[to++] = t
				lines.push(line)
				columns.push(position - columnBase - 1)
			}

			// Add parametrized token
			@inline fun addn(t: Token, p: String) {
				params[to] = p
				add(t)
			}

			// Add parametrized token with meta
			@inline fun addm(t: Token, p: String, m: Meta) {
				params[to] = p
				meta[to] = m
				add(t)
			}

			@inline fun curPos() {
				return position - columnBase - 1
			}
			// Getting bytes
			@inline fun get_8(pos) {
				return bytes[pos]
			}
			// Not out of length
			@inline fun not_eof(): Bool {
				return (position < len)
			}
			// Lines
			@inline fun new_line() {
				line++
				columnBase = position
			}

			@inline fun fail(message: String, erline: Int? = null, column: Int? = null, filename: String? = null) {
				var erline = erline != null ? erline : line
				var column = column != null ? column : curPos()
				var filename = filename != null ? filename : fileName
				return new CompilerErrors([new CompilerError(Fail.LexerError, message, erline, column, filename)])
			}

			// UTF-8 with BOM
			if len > 2, get_8(0) == 239, get_8(1) == 187, get_8(2) == 191 {
				position += 3
			}

			// Ignore #!shebang until end of line
			if len > 2, get_8(0) == "#".charCodeAt(0), get_8(1) == "!".charCodeAt(0) { while (position < len && get_8(position) != 10) {
				position++
			}}

			// Lexer main loop
			while (position < len) {
				// Variable
				var _8 = 0 // Current byte value

				// Whitespace
				/*var _8 = get_8(position)
				while ((_8 <= 32) && (position < len)) {
					if (_8 == "\n".charCodeAt(0)) {
						new_line()
						//position++
					}
					position++
					_8 = get_8(position)
				}*/

				do {
					// \r\n case works fine, but we dont support \r-only case!
					_8 = get_8(position)
					if (_8 == /*"\n".charCodeAt(0)*/10) {
						new_line()
					}
					//position++
				} while (_8 <= 32 && (++position < len))

				if (!not_eof()) { break }

				// Current two-byte value
				var _16 = (len - position) > 1 ? _8 | (get_8(position + 1) << 8) : _8

				// Comments
				if (_8 == "/".charCodeAt(0)) {
					// // Comment
					if (_16 == 0x2f2f) {
						var pos = position + 2
						while (get_8(position) != /*"\n".charCodeAt(0)*/10 && not_eof()) {
							position++
						}
						continue
					}
					// /** Doc **/
					if (_16 == 10799 && get_8(position + 2) == "*".charCodeAt(0)) {
						position += 3
						p = position
						while (not_eof()) {
							var _32 = (len - position) > 3 ? bytes.readUInt32LE(position) : get_8(position)
							if ((_32 & 0xFF) == /*"\n".charCodeAt(0)*/10) {new_line()}
							else if ((_32 & 0xFFFFFF) == 3090986) {break}
							position++
						}
						if (!not_eof()) {
							throw fail("Unclosed doc-comment")
						}
						addn(Token.LDoc, bytes.toString('utf8', p, position))
						position += 3
						continue
					}
					// /* Comment */
					if (_16 == 10799) {
						var pos = position + 2
						p = 0 // Nesting level
						position += 2
						while (not_eof()) {
							_16 = (len - position) > 1 ? bytes.readUInt16LE(position) : get_8(position)
							if ((_16 & 0xFF) == /*"\n".charCodeAt(0)*/10) { new_line() }
							else if (_16 == 12074 && p > 0) { p-- }
							else if (_16 == 10799) { p++ }
							else if (_16 == 12074 && p == 0) { break }
							position++
						}
						position += 2
						continue
					}
				}

				// Identifiers and keywords
				// A-z _
				if (((_8 & 95) >= 65 && (_8 & 95) <= 90) || (_8 == 95)) {
					let titlechar = _8
					p = position + 1
					_8 = get_8(p)
					while (p < len && isident[_8] != 0) {
						_8 = get_8(++p)
					}
					s = bytes.toString('ascii', position, p)
					let t: Token? = ((_16 & 0xFF) <= 90) ? null : kwd.get(s)
					if let t = t {
						add(t)
					} else {
						if (titlechar >= 65 && titlechar <= 90) {
							addn(Token.LUpper, s)
						}
						else {
							addn(Token.LLower, s)
						}
					}
					position = p
					continue
				}

				// `Backtick`
				if (_8 == 96) {
					position++
					let pos = position
					while (not_eof()) {
						if get_8(position) == 96, get_8(position + 1) == 96 {
							position++
							position++
							continue
						}

						if (get_8(position) == 96) {
							break
						}

						if (get_8(position) == 10) {
							new_line()
						}

						position++
					}
					var result = bytes.toString('utf8', pos, position)
					// Removes double backticks
					if (result.indexOf('``') != -1) {
						result = result.split('``').join('')
					}
					addn(Token.LBacktick, result)
					position++
					continue
				}

				// ...
				if (_16 == 11822 && (get_8(position + 2) == ".".charCodeAt(0))) {
					add(Token.Interval)
					position += 3
					continue
				}

				// >>>
				if (_16 == 15934 && (get_8(position + 2) == ">".charCodeAt(0))) {
					add(Token.OpUShr)
					position += 3
					continue
				}

				// 16 bit ops
				// Verify & extract
				let hash = simplehash(_16)
				if (_16 == op16token.readUInt16LE(hash * 2)) {
					add(op16token[hash + 512] as! Token)
					position += 2
					continue
				}

				// 8 bit ops
				// TODO we can keep _8 as Token, if say '+' == ASCII code of '+'
				// and avoid using ops8a
				let found = ops8a[_8] as! Token
				if (found != Token.Eof) {
					add(found)
					position++
					continue
				}

				// Strings
				// "" and ''
				if (_8 < 40) {
					p = _8 // Remember, if double/singlequoted
					position++
					let pos = position

					// We don't do string \() interpolation here,
					// coz pretty printer
					while (get_8(position) != p && not_eof()) {
						if (get_8(position) == /*"\n".charCodeAt(0)*/10) {
							new_line()
						}
						if (get_8(position) == '\\'.charCodeAt(0)) {
							position += 2
							continue
						}
						_16 = (len - position) > 1 ? bytes.readUInt16LE(position) : get_8(position)
						position++
					}
					var result = bytes.toString('utf8', pos, position)
					// Convert `\r\n` to `\n`
					if (result.indexOf('\r\n') != -1) {
						result = result.split('\r\n').join('\n')
					}
					addn(Token.LString, result)
					position++
					continue
				}

				// Int Hex 0x123ABC
				if (_16 == 30768) {
					p = position
					p += 2
					_8 = get_8(position)

					while (
						(_8 >= 65 && _8 <= 70) // A...F
						||
						(_8 >= 48 && _8 <= 57) // 0...9
						||
						(_8 >= 97 && _8 <= 102) // a...f
					) {
						_8 = get_8(++p)
					}

					if (p - position == 2) {
						throw fail("Integer `0x` not allowed!")
					}

					var m = Meta.Default
					var offset = 0

					if (get_8(p) == "n".charCodeAt(0)) {
						m = Meta.BigInt
						offset = 1
					} else if (get_8(p) == "i".charCodeAt(0)) {
						// TODO yeah this should be shorter
						let header = bytes.readUInt16LE(p + 1)
						if (get_8(p + 1) == "8".charCodeAt(0)) {
							m = Meta.Int8
							offset = 2
						} else if (header == "3".charCodeAt(0) + "2".charCodeAt(0) * 256) {
							m = Meta.Int32
							offset = 3
						} else if (header == "6".charCodeAt(0) + "4".charCodeAt(0) * 256) {
							m = Meta.Int64
							offset = 3
						} else if (header == "1".charCodeAt(0) + "6".charCodeAt(0) * 256) {
							m = Meta.Int16
							offset = 3
						}
					} else if (get_8(p) == "u".charCodeAt(0)) {
						let header = bytes.readUInt16LE(p + 1)
						if (get_8(p + 1) == "8".charCodeAt(0)) {
							m = Meta.UInt8
							offset = 2
						} else if (header == "3".charCodeAt(0) + "2".charCodeAt(0) * 256) {
							m = Meta.UInt32
							offset = 3
						} else if (header == "6".charCodeAt(0) + "4".charCodeAt(0) * 256) {
							m = Meta.UInt64
							offset = 3
						} else if (header == "1".charCodeAt(0) + "6".charCodeAt(0) * 256) {
							m = Meta.UInt16
							offset = 3
						}
					}

					addm(Token.LInt, bytes.toString('ascii', position, p), m)
					position = p + offset

					continue
				}

				// Float & Int
				if (_8 < 58) {
					p = position
					_8 = get_8(p)
					var found: Token = Token.LInt
					while (
						_8 >= 48 && _8 <= 57 // 0...9
					) {
						_8 = get_8(++p)
					}

					// Float
					// point
					if (_8 == ".".charCodeAt(0) && get_8(p + 1) != ".".charCodeAt(0)) {
						_8 = get_8(++p)
						while (
							_8 >= 48 && _8 <= 57 // 0...9
						) {
							_8 = get_8(++p)
						}
						found = Token.LFloat
					}

					// exponent
					if (_8 == "e".charCodeAt(0) || _8 == "E".charCodeAt(0)) {
						_8 = get_8(++p)

						if (_8 == "+".charCodeAt(0) || _8 == "-".charCodeAt(0)) {
							_8 = get_8(++p)
						}

						while (
							_8 >= 48 && _8 <= 57 // 0...9
						) {
							_8 = get_8(++p)
						}
						found = Token.LFloat
					}

					var m = Meta.Default
					var offset = 0

					// TODO reuse code
					if (get_8(p) == "n".charCodeAt(0)) {
						m = Meta.BigInt
						offset = 1
					} else if (get_8(p) == "i".charCodeAt(0)) {
						// TODO yeah this should be shorter
						let header = bytes.readUInt16LE(p + 1)
						if (get_8(p + 1) == "8".charCodeAt(0)) {
							m = Meta.Int8
							offset = 2
						} else if (header == "3".charCodeAt(0) + "2".charCodeAt(0) * 256) {
							m = Meta.Int32
							offset = 3
						} else if (header == "6".charCodeAt(0) + "4".charCodeAt(0) * 256) {
							m = Meta.Int64
							offset = 3
						} else if (header == "1".charCodeAt(0) + "6".charCodeAt(0) * 256) {
							m = Meta.Int16
							offset = 3
						}
					} else if (get_8(p) == "u".charCodeAt(0)) {
						let header = bytes.readUInt16LE(p + 1)
						if (get_8(p + 1) == "8".charCodeAt(0)) {
							m = Meta.UInt8
							offset = 2
						} else if (header == "3".charCodeAt(0) + "2".charCodeAt(0) * 256) {
							m = Meta.UInt32
							offset = 3
						} else if (header == "6".charCodeAt(0) + "4".charCodeAt(0) * 256) {
							m = Meta.UInt64
							offset = 3
						} else if (header == "1".charCodeAt(0) + "6".charCodeAt(0) * 256) {
							m = Meta.UInt16
							offset = 3
						}
					} else if (get_8(p) == "f".charCodeAt(0)) {
						let header = bytes.readUInt16LE(p + 1)
						if (header == "3".charCodeAt(0) + "2".charCodeAt(0) * 256) {
							m = Meta.Float32
							offset = 3
						}
					}

					addm(found, bytes.toString('ascii', position, p), m)
					position = p + offset
					continue
				}

				// Error
				if (position >= len) {
					break
				}
				throw fail('Unexpected character ' + String.fromCharCode(_8))
				break
			}
			return new Tokens(tokens, to, params, lines, columns, fileName, meta)
	}

	static fun init() {
		// Aplhanumeric _
		for _8 in 256 {
			isident[_8] =
				((_8 >= 65 && _8 <= 90) // A...Z
					||
					(_8 >= 48 && _8 <= 57) // 0...9
					||
					(_8 >= 97 && _8 <= 122) // a...z
					|| _8 == 95) ? 128 : 0
					// _
		}

		// Aplhanumeric _
		for _8 in 256 {
			isident[_8] =
				((_8 >= 65 && _8 <= 90) // A...Z
					||
					(_8 >= 48 && _8 <= 57) // 0...9
					||
					(_8 >= 97 && _8 <= 122) // a...z
					|| _8 == 95) ? 128 : 0
					// _
		}

		// Keywords
		kwd =
			[
				"_" : Token.Underscore,
				"as" : Token.KAs,
				"break" : Token.KBreak,
				"case" : Token.KCase,
				"catch" : Token.KCatch,
				"class" : Token.KClass,
				"continue" : Token.KContinue,
				"do" : Token.KDo,
				"else" : Token.KElse,
				"enum" : Token.KEnum,
				"extends" : Token.KExtends,
				"declare" : Token.KDeclare,
				"false" : Token.KFalse,
				"for" : Token.KFor,
				"fun" : Token.KFun,
				"if" : Token.KIf,
				"implements" : Token.KImplements,
				"import" : Token.KImport,
				"in" : Token.KIn,
				"interface" : Token.KInterface,
				"let" : Token.KLet,
				"new" : Token.KNew,
				"null" : Token.KNull,
				"private" : Token.KPrivate,
				"return" : Token.KReturn,
				"static" : Token.KStatic,
				"super" : Token.KSuper,
				"switch" : Token.KSwitch,
				"this" : Token.KThis,
				"throw" : Token.KThrow,
				"true" : Token.KTrue,
				"try" : Token.KTry,
				"var" : Token.KVar,
				"while" : Token.KWhile,
				"and" : Token.OpBoolAnd,
				"or" : Token.OpBoolOr,
				"not" : Token.OpNot,
				"is" : Token.KIs
			]

		// 1-byte op
		let ops8: [Int : Token] =
			[
				"@".charCodeAt(0)  : Token.At,
				"$".charCodeAt(0)  : Token.Query,
				"#".charCodeAt(0)  : Token.Sharp,
				"!".charCodeAt(0)  : Token.OpNot,
				"%".charCodeAt(0)  : Token.OpMod,
				"&".charCodeAt(0)  : Token.OpAnd,
				"(".charCodeAt(0)  : Token.POpen,
				")".charCodeAt(0)  : Token.PClose,
				"*".charCodeAt(0)  : Token.OpMult,
				"+".charCodeAt(0)  : Token.OpAdd,
				",".charCodeAt(0)  : Token.Comma,
				"-".charCodeAt(0)  : Token.OpSub,
				".".charCodeAt(0)  : Token.Dot,
				"/".charCodeAt(0)  : Token.OpDiv,
				":".charCodeAt(0)  : Token.Colon,
				";".charCodeAt(0)  : Token.Semicolon,
				"<".charCodeAt(0)  : Token.OpLt,
				"=".charCodeAt(0)  : Token.OpAssign,
				">".charCodeAt(0)  : Token.OpGt,
				"?".charCodeAt(0)  : Token.Question,
				"[".charCodeAt(0)  : Token.BkOpen,
				"\\".charCodeAt(0) : Token.OpIntDiv,
				"]".charCodeAt(0)  : Token.BkClose,
				"^".charCodeAt(0)  : Token.OpXor,
				"{".charCodeAt(0)  : Token.BrOpen,
				"|".charCodeAt(0)  : Token.OpOr,
				"}".charCodeAt(0)  : Token.BrClose,
				"~".charCodeAt(0)  : Token.OpNegBits
			]

		for key in ops8.keys() {
			ops8a[key] = ops8.get(key)
		}

		// 2-byte op
		// Hash = charCodeAt(0) + charCodeAt(1)*256
		let ops16: [Int : Token] =
			[
				11051 : Token.OpIncrement, // ++
				11565 : Token.OpDecrement, // --
				15420 : Token.OpShl,       // <<
				15649 : Token.OpNotEq,     // !=
				15676 : Token.OpLte,       // <=
				15677 : Token.OpEq,        // ==
				15678 : Token.OpGte,       // >=
				15934 : Token.OpShr,       // >>
				31868 : Token.OpBoolOr,    // ||
				9766  : Token.OpBoolAnd,   // &&
				15933 : Token.OpArrow,     // =>
				11839 : Token.OpChain     // ?.
			]

		for key1 in ops16.keys() {
			for key2 in ops16.keys() {
				if (key1 != key2 && simplehash(key1) == simplehash(key2)) {
					throw new CompilerError(Fail.LexerError, "2-byte op hash collision: " + key1 + " " + key2, 0, 0, "INTERNAL")
				}
			}
		}

		for key in ops16.keys() {
			let hash = simplehash(key)
			// Verify
			op16token.writeUInt16LE(key, hash * 2)
			// Tokens
			op16token[hash + 512] = ops16.get(key)
		}
		return
	}

	// Free of collisions for current set
	@inline static fun simplehash(val: Int): Int {
		return ((val & 0xff) + (((val >> (8 * 1)) & 0xff) << 3)) & 0xEF
	}

	// Pre-calculated array of is byte in A-z 0-9 _
	static let isident: Buffer = Buffer.alloc(256)

	// Pre-calculated array of is byte in A-Z
	static let isUpper: Buffer = Buffer.alloc(256)

	//// TODO Pre-calculated array of is byte in a-z
	// TODO static var isLower: Buffer<Int>

	// Single-byte operators and symbols
	static let ops8a: Buffer = Buffer.alloc(256)

	// Double-byte operators and symbols
	static let op16token: Buffer = Buffer.alloc(768)

	// Keywords
	static var kwd: [String : Token]
}
