// The Hexa Compiler
// Copyright (C) 2021  Oleg Petrenko
// Copyright (C) 2018  Bogdan Danylchenko
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Lesser General Public License as published by
// the Free Software Foundation, version 3 of the License.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Lesser General Public License for more details.
//
// You should have received a copy of the GNU Lesser General Public License
// along with this program.  If not, see <https://www.gnu.org/licenses/>.

	// See: `/docs/lexer.md`
	class TestLexer {
		static fun test() {
			console.log("TestLexer begin")

			// Shebang
			compare("#!/bin", [], [])
			compare("#!/bin\n", [], [])
			compare("#!/bin\n//", [], [])
			compare("#!/bin\r\n123", [Token.LInt], ["123"]) // May not work on Linux because of \r if no `bin\r` file exist
			compare("#!/bin\n\r123", [Token.LInt], ["123"]) // \r is completely ignored by lexer
			compare("#!/bin\n123", [Token.LInt], ["123"])

			// Empty (whitespace, comments)
			compare("", [], [])
			compare("\n", [], [])
			compare("\n\n", [], [])
			compare("\r\r\n\r\n\r\t", [], [])
			compare(" ", [], [])
			compare("  ", [], [])
			compare("	", [], [])
			compare("		", [], [])
			compare("	 	", [], [])
			compare("/* */", [], [])
			compare("/*\n*/", [], [])
			compare("//", [], [])
			compare("// ", [], [])
			compare("//\n", [], [])

			// Int
			compare("123", [Token.LInt], ["123"])
			compare(" 0 ", [Token.LInt], ["0"])
			compare("0", [Token.LInt], ["0"])
			compare("1 2 3", [Token.LInt, Token.LInt, Token.LInt], ["1", "2", "3"])
			compare("0x1", [Token.LInt], ["0x1"])
			compare("0x0", [Token.LInt], ["0x0"])
			compare("0xF", [Token.LInt], ["0xF"])
			compare("0xFA", [Token.LInt], ["0xFA"])
			compare("0xFABCDEF", [Token.LInt], ["0xFABCDEF"])
			compare("0x1F2A3B4C5D6E7F0", [Token.LInt], ["0x1F2A3B4C5D6E7F0"])
			compare("-123", [Token.OpSub, Token.LInt], ["-", "123"])
			compare("+123", [Token.OpAdd, Token.LInt], ["+", "123"])

			// Float
			compare("0.123", [Token.LFloat], ["0.123"])
			compare("0.0", [Token.LFloat], ["0.0"])
			compare("0.0e+1", [Token.LFloat], ["0.0e+1"])
			compare("0.0E-1", [Token.LFloat], ["0.0E-1"])
			compare("0E-123", [Token.LFloat], ["0E-123"])
			compare("123e123", [Token.LFloat], ["123e123"])
			compare("1 2.0 3", [Token.LInt, Token.LFloat, Token.LInt], ["1", "2.0", "3"])

			// String
			compare("'s'", [Token.LString], ["'s'"])
			compare('"s"', [Token.LString], ["'s'"]) // TODO Quotes `"` and `'` should be differentiated for pretty printing
			compare("\"s\"", [Token.LString], ["'s'"]) // TODO All `\*` should be kept for pretty printing
			compare("`s`", [Token.LBacktick], ["`s`"])
			compare("`aaa bbb``ccc` `ddd`", [Token.LBacktick, Token.LBacktick], ["`aaa bbbccc`", "`ddd`"])
			compare("````````", [Token.LBacktick], ["``"])
			compare("``", [Token.LBacktick], ["``"])
			compare("``\n", [Token.LBacktick], ["``"])
			compare("``\n``", [Token.LBacktick, Token.LBacktick], ["``", "``"])

			// String consistency - repair \r\n to \n for non-raw ones
			compare("'s\n'", [Token.LString], ["'s\n'"]) // '
			compare("'s\r\n'", [Token.LString], ["'s\n'"]) // '
			compare("'s
				s'", [Token.LString], ["'s\n\t\t\t\ts'"]) // Test on actual code
			compare('"s\n"', [Token.LString], ["'s\n'"]) // "
			compare('"s\r\n"', [Token.LString], ["'s\n'"]) // "
			compare('"\r\ns\r\n"', [Token.LString], ["'\ns\n'"]) // "
			compare("`s\n`", [Token.LBacktick], ["`s\n`"]) // `
			compare("`s\r\n`", [Token.LBacktick], ["`s\r\n`"]) // `
			compare("`s\r`", [Token.LBacktick], ["`s\r`"]) // `
			compare("`s\\r`", [Token.LBacktick], ["`s\\r`"]) // `

			// Identifiers
			compare("T", [Token.LUpper], ["T"])
			compare("T val", [Token.LUpper, Token.LLower], ["T", "val"])
			compare("T val Type", [Token.LUpper, Token.LLower, Token.LUpper], ["T", "val", "Type"])
			compare("_T", [Token.LLower], ["_T"])
			compare("v", [Token.LLower], ["v"])
			compare("_v", [Token.LLower], ["_v"])
			compare("_123", [Token.LLower], ["_123"])

			// Multichar tokens
			compare(" } ", [Token.BrClose], ["}"])
			compare("==", [Token.OpEq], ["=="])
			compare("===", [Token.OpEq, Token.OpAssign], ["==", "="])
			compare("== =", [Token.OpEq, Token.OpAssign], ["==", "="])
			compare("= ==", [Token.OpAssign, Token.OpEq], ["=", "=="])
			compare("=====", [Token.OpEq, Token.OpEq, Token.OpAssign], ["==", "==", "="])
			compare(
				"> >> >>> . .. ...",
				[Token.OpGt, Token.OpShr, Token.OpUShr, Token.Dot, Token.Dot, Token.Dot, Token.Interval],
				[">", ">>", ">>>", ".", ".", ".", "..."]
			)
			compare(
				">>>>>>.......",
				[Token.OpUShr, Token.OpUShr, Token.Interval, Token.Interval, Token.Dot],
				[">>>", ">>>", "...", "...", "."]
			)

			// Position of tokens

			// Position of errors

			console.log("TestLexer done \(Math.round((passed/overall)*100))% (\(passed)/\(overall))")
		}

		static var passed = 0
		static var overall = 0

		/// Fix invisible chars like \t\r\n
		static fun renderInvisibleChars(input: String): String {
			return input
			.split('\r').join('\\r')
			.split('\n').join('\\n')
			.split('\t').join('\\t')
		}

		/// Token and value equality
		static fun compare(
			input: String,
			expect: [Token],
			expectValue: [String],
			expectColumn: [Int] = null,
			expectLine: [Int] = null
		): Void {
			expect.push(Token.Eof)
			let output = Lexer.tokenize(Buffer.fromString(input), "TEST")
			var pos = 0

			fun incorrect(text: String) {
				var got = Token.stringify(output.token[pos], output.value[pos])
				got = renderInvisibleChars(got)
				console.log('Incorrect token `\(got)` in string `\(renderInvisibleChars(input))` at index \(pos)')
				console.log(text)
			}

			overall++
			for ex in expect {
				if (ex == Token.Eof) {
					break
				}

				if (ex != output.token[pos]) {
					incorrect('Expected `\(renderInvisibleChars(Token.stringify(ex)))`')
					return
				}

				let value = Token.stringify(output.token[pos], output.value[pos])
				if (expectValue[pos] != value) {
					incorrect('Expected value `\(renderInvisibleChars(expectValue[pos]))` but got `\(renderInvisibleChars(value))`')
					return
				}

				pos++
			}
			passed++
		}
	}
