// The Hexa Compiler
// Copyright (C) 2020  Oleg Petrenko
// Copyright (C) 2018  Bogdan Danylchenko
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Lesser General Public License as published by
// the Free Software Foundation, version 3 of the License.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Lesser General Public License for more details.
//
// You should have received a copy of the GNU Lesser General Public License
// along with this program.  If not, see <https://www.gnu.org/licenses/>.

module
	// Array of resulting tokens
	class Tokens {
		var token: Buffer<Token> // let = new.
		// Values of an unique lexemes, like integers and strings
		var value: [String]
		var length: Int
		var line: [Int]
		var column: [Int]
		var fileName: String

		new (tokens, length, values, lines, columns, fileName) {
			this.token = tokens
			this.length = length
			this.value = values
			this.line = lines
			this.column = columns
			this.fileName = fileName
		}
	}

	// Takes UTF-8 text and returns tokens
	// See: `/docs/lexer.md`
	class Lexer {
		static function tokenize(bytes: Buffer<Int>, fileName: String): Tokens {
			// Variables
			var position = 0
			let len = bytes.length
			var to = 0
			var s = ""
			var p = 0
			var line = 1
			var columnBase = 0

			// Prefetch
			let params = []
			let tokens = Buffer.alloc(len + 1)
			var lines = []
			var columns = []

			// Helpers
			// Just add plain token
			@inline function add(t: Token) {
				tokens[to++] = t
				lines.push(line)
				columns.push(position - columnBase - 1)
			}
			// Add parametrized token
			@inline function addn(t: Token, p: String) {
				params[to] = p
				add(t)
			}

			@inline function curPos() return position - columnBase - 1
			// Getting bytes
			@inline function get_8(pos) return bytes[pos]
			// Not out of length
			@inline function not_eof(): Bool return (position < len)
			// Lines
			@inline function new_line() {
				line++
				columnBase = position
			}

			@inline function fail(message: String, erline: Int? = null, column: Int? = null, filename: String? = null) {
				var erline = erline != null ? erline : line
				var column = column != null ? column : curPos()
				var filename = filename != null ? filename : fileName
				return new CompilerError(Fail.LexerError, message, erline, column, filename)
			}

			// UTF-8 with BOM
			if (len > 2, get_8(0) == 239, get_8(1) == 187, get_8(2) == 191) position += 3

			// Ignore #!shebang until end of line
			if (len > 2, get_8(0) == "#".charCodeAt(0), get_8(1) == "!".charCodeAt(0)) while (position < len && get_8(position) != 10) {
				position++
			}

			// Lexer main loop
			while (position < len) {
				// Variable
				var _8 = 0 // Current byte value

				// Whitespace
				/*var _8 = get_8(position)
				while ((_8 <= 32) && (position < len)) {
					if (_8 == "\n".charCodeAt(0)) {
						new_line()
						//position++
					}
					position++
					_8 = get_8(position)
				}*/

				do {
					// \r\n case works fine, but we dont support \r-only case!
					_8 = get_8(position)
					if (_8 == /*"\n".charCodeAt(0)*/10) {
						new_line()
					}
					//position++
				} while (_8 <= 32 && (++position < len))
				if (!not_eof()) break

				// Current two-byte value
				var _16 = (len - position) > 1 ? _8 | (get_8(position + 1) << 8) : _8

				// Comments
				if (_8 == "/".charCodeAt(0)) {
					// // Comment
					if (_16 == 0x2f2f) {
						var pos = position + 2
						while (get_8(position) != /*"\n".charCodeAt(0)*/10 && not_eof()) {
							position++
						}
						continue
					}
					// /** Doc **/
					if (_16 == 10799 && get_8(position + 2) == "*".charCodeAt(0)) {
						position += 3
						p = position
						while (not_eof()) {
							var _32 = (len - position) > 3 ? bytes.readUInt32LE(position) : get_8(position)
							if ((_32 & 0xFF) == /*"\n".charCodeAt(0)*/10) new_line()
							else if ((_32 & 0xFFFFFF) == 3090986) break
							position++
						}
						if (!not_eof())
							throw fail("Unclosed doc-comment")
						addn(Token.LDoc, bytes.toString('utf8', p, position))
						position += 3
						continue
					}
					// /* Comment */
					if (_16 == 10799) {
						var pos = position + 2
						p = 0 // Nesting level
						position += 2
						while (not_eof()) {
							_16 = (len - position) > 1 ? bytes.readUInt16LE(position) : get_8(position)
							if ((_16 & 0xFF) == /*"\n".charCodeAt(0)*/10) new_line()
							else if (_16 == 12074 && p > 0) p--
							else if (_16 == 10799) p++
							else if (_16 == 12074 && p == 0) break
							position++
						}
						position += 2
						continue
					}
				}

				// Identifiers and keywords
				// A-z _
				if (((_8 & 95) >= 65 && (_8 & 95) <= 90) || (_8 == 95)) {
					let titlechar = _8
					p = position + 1
					_8 = get_8(p)
					while (p < len && isident[_8] != 0) _8 = get_8(++p)
					s = bytes.toString('ascii', position, p)
					let t: Token? = ((_16 & 0xFF) <= 90) ? null : kwd.get(s)
					if (let t = t) {
						add(t)
					} else {
						if (titlechar >= 65 && titlechar <= 90) {
							addn(Token.LUpper, s)
						}
						else {
							addn(Token.LLower, s)
						}
					}
					position = p
					continue
				}

				// `Backtick`
				if (_8 == 96) {
					position++
					let pos = position
					while (not_eof()) {
						if (get_8(position) == 96, get_8(position + 1) == 96) {
							position++
							position++
							continue
						}

						if (get_8(position) == 96) {
							break
						}

						if (get_8(position) == 10) new_line()

						position++
					}
					var result = bytes.toString('utf8', pos, position)
					// Removes double backticks
					if (result.indexOf('``') != -1) result = result.split('``').join('')
					addn(Token.LBacktick, result)
					position++
					continue
				}

				// ...
				if (_16 == 11822 && (get_8(position + 2) == ".".charCodeAt(0))) {
					add(Token.Interval)
					position += 3
					continue
				}

				// >>>
				if (_16 == 15934 && (get_8(position + 2) == ">".charCodeAt(0))) {
					add(Token.OpUShr)
					position += 3
					continue
				}

				// 16 bit ops
				// Verify & extract
				let hash = simplehash(_16)
				if (_16 == op16token.readUInt16LE(hash * 2)) {
					add(op16token[hash + 512])
					position += 2
					continue
				}

				// 8 bit ops
				let found = ops8a[_8]
				if (found != Token.Eof) {
					add(found)
					position++
					continue
				}

				// Strings
				// "" and ''
				if (_8 < 40) {
					p = _8 // Remember, if double/singlequoted
					position++
					let pos = position

					// We don't do string \() interpolation here,
					// coz pretty printer
					while (get_8(position) != p && not_eof()) {
						if (get_8(position) == /*"\n".charCodeAt(0)*/10) new_line()
						if (get_8(position) == '\\'.charCodeAt(0)) {
							position += 2
							continue
						}
						_16 = (len - position) > 1 ? bytes.readUInt16LE(position) : get_8(position)
						position++
					}
					var result = bytes.toString('utf8', pos, position)
					// Convert `\r\n` to `\n`
					if (result.indexOf('\r\n') != -1) result = result.split('\r\n').join('\n')
					addn(Token.LString, result)
					position++
					continue
				}

				// Int Hex 0x123ABC
				if (_16 == 30768) {
					p = position
					p += 2
					_8 = get_8(position)
					while (
						(_8 >= 65 && _8 <= 70) // A...F
						||
						(_8 >= 48 && _8 <= 57) // 0...9
						||
						(_8 >= 97 && _8 <= 102) // a...f
					) {
						_8 = get_8(++p)
					}
					if (p - position == 2)
						throw fail("Integer `0x` not allowed!")
					addn(Token.LInt, bytes.toString('ascii', position, p))
					position = p
					continue
				}

				// Float & Int
				if (_8 < 58) {
					p = position
					_8 = get_8(p)
					var found: Token = Token.LInt
					while (
						_8 >= 48 && _8 <= 57 // 0...9
					) {
						_8 = get_8(++p)
					}

					// Float
					// point
					if (_8 == ".".charCodeAt(0) && get_8(p + 1) != ".".charCodeAt(0)) {
						_8 = get_8(++p)
						while (
							_8 >= 48 && _8 <= 57 // 0...9
						) {
							_8 = get_8(++p)
						}
						found = Token.LFloat
					}

					// exponent
					if (_8 == "e".charCodeAt(0) || _8 == "E".charCodeAt(0)) {
						_8 = get_8(++p)
						if (_8 == "+".charCodeAt(0) || _8 == "-".charCodeAt(0)) _8 = get_8(++p)
						while (
							_8 >= 48 && _8 <= 57 // 0...9
						) {
							_8 = get_8(++p)
						}
						found = Token.LFloat
					}
					addn(found, bytes.toString('ascii', position, p))
					position = p
					continue
				}

				// Error
				if (position >= len) break
				throw fail('Unexpected character ' + String.fromCharCode(_8))
				break
			}
			return new Tokens(tokens, to, params, lines, columns, fileName)
		}

		static function init() {
			// Aplhanumeric _
			isident = Buffer.alloc(256)
			for (_8 in 256)
				isident[_8] =
					((_8 >= 65 && _8 <= 90) // A...Z
					 ||
					 (_8 >= 48 && _8 <= 57) // 0...9
					 ||
					 (_8 >= 97 && _8 <= 122) // a...z
					 || _8 == 95) ? 128 : 0
					 // _

			// Aplhanumeric _
			isUpper = Buffer.alloc(256)
			for (_8 in 256)
				isident[_8] =
					((_8 >= 65 && _8 <= 90) // A...Z
					 ||
					 (_8 >= 48 && _8 <= 57) // 0...9
					 ||
					 (_8 >= 97 && _8 <= 122) // a...z
					 || _8 == 95) ? 128 : 0
					 // _

			// Keywords
			kwd =
				[
					"_" : Token.Underscore,
					"as" : Token.KAs,
					"break" : Token.KBreak,
					"case" : Token.KCase,
					"catch" : Token.KCatch,
					"class" : Token.KClass,
					"continue" : Token.KContinue,
					"do" : Token.KDo,
					"else" : Token.KElse,
					"enum" : Token.KEnum,
					"extends" : Token.KExtends,
					"export" : Token.KExport,
					"declare" : Token.KDeclare,
					"false" : Token.KFalse,
					"for" : Token.KFor,
					"function" : Token.KFunction,
					"from" : Token.KFrom,
					"if" : Token.KIf,
					"implements" : Token.KImplements,
					"import" : Token.KImport,
					"in" : Token.KIn,
					"interface" : Token.KInterface,
					"let" : Token.KLet,
					"new" : Token.KNew,
					"null" : Token.KNull,
					"module" : Token.KModule,
					"private" : Token.KPrivate,
					"return" : Token.KReturn,
					"static" : Token.KStatic,
					"super" : Token.KSuper,
					"switch" : Token.KSwitch,
					"this" : Token.KThis,
					"throw" : Token.KThrow,
					"true" : Token.KTrue,
					"try" : Token.KTry,
					"using" : Token.KUsing,
					"var" : Token.KVar,
					"while" : Token.KWhile,
					"is" : Token.KIs
				]

			// 1-byte op
			let ops8: [Int : Token] =
				[
					"@".charCodeAt(0)  : Token.At,
					"$".charCodeAt(0)  : Token.Query,
					"#".charCodeAt(0)  : Token.Sharp,
					"!".charCodeAt(0)  : Token.OpNot,
					"%".charCodeAt(0)  : Token.OpMod,
					"&".charCodeAt(0)  : Token.OpAnd,
					"(".charCodeAt(0)  : Token.POpen,
					")".charCodeAt(0)  : Token.PClose,
					"*".charCodeAt(0)  : Token.OpMult,
					"+".charCodeAt(0)  : Token.OpAdd,
					",".charCodeAt(0)  : Token.Comma,
					"-".charCodeAt(0)  : Token.OpSub,
					".".charCodeAt(0)  : Token.Dot,
					"/".charCodeAt(0)  : Token.OpDiv,
					":".charCodeAt(0)  : Token.Colon,
					";".charCodeAt(0)  : Token.Semicolon,
					"<".charCodeAt(0)  : Token.OpLt,
					"=".charCodeAt(0)  : Token.OpAssign,
					">".charCodeAt(0)  : Token.OpGt,
					"?".charCodeAt(0)  : Token.Question,
					"[".charCodeAt(0)  : Token.BkOpen,
					"\\".charCodeAt(0) : Token.OpIntDiv,
					"]".charCodeAt(0)  : Token.BkClose,
					"^".charCodeAt(0)  : Token.OpXor,
					"{".charCodeAt(0)  : Token.BrOpen,
					"|".charCodeAt(0)  : Token.OpOr,
					"}".charCodeAt(0)  : Token.BrClose,
					"~".charCodeAt(0)  : Token.OpNegBits
				]
			ops8a = Buffer.alloc(256)
			for (key in ops8.keys()) ops8a[key] = ops8.get(key)

			// 2-byte op
			// Hash = charCodeAt(0) + charCodeAt(1)*256
			let ops16: [Int : Token] =
				[
					11051 : Token.OpIncrement, // ++
					11565 : Token.OpDecrement, // --
					15420 : Token.OpShl,       // <<
					15649 : Token.OpNotEq,     // !=
					15676 : Token.OpLte,       // <=
					15677 : Token.OpEq,        // ==
					15678 : Token.OpGte,       // >=
					15934 : Token.OpShr,       // >>
					31868 : Token.OpBoolOr,    // ||
					9766  : Token.OpBoolAnd,   // &&
					15933 : Token.OpArrow,     // =>
					11839 : Token.OpChain     // ?.
				]
			for (key1 in ops16.keys()) {
				for (key2 in ops16.keys()) {
					if (key1 != key2 && simplehash(key1) == simplehash(key2)) {
						throw new CompilerError(Fail.LexerError, "2-byte op hash collision: " + key1 + " " + key2, 0, 0, "INTERNAL")
					}
				}
			}

			op16token = Buffer.alloc(768)
			for (key in ops16.keys()) {
				let hash = simplehash(key)
				// Verify
				op16token.writeUInt16LE(key, hash * 2)
				// Tokens
				op16token[hash + 512] = ops16.get(key)
			}
			return
		}

		// Free of collisions for current set
		@inline static function simplehash(val: Int): Int {
			return ((val & 0xff) + (((val >> (8 * 1)) & 0xff) << 3)) & 0xEF
		}

		// Pre-calculated array of is byte in A-z 0-9 _
		static var isident: Buffer<Int>


		// Pre-calculated array of is byte in A-Z
		static var isUpper: Buffer<Int>
		// Pre-calculated array of is byte in a-z
		static var isLower: Buffer<Int>

		// Single-byte operators and symbols
		static var ops8a: Buffer<Token>

		// Double-byte operators and symbols
		static var op16token: Buffer<Token>

		// Keywords
		static var kwd: [String : Token]
	}
